{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Specify the path to the .env file if it's not in the same directory\n",
    "load_dotenv(dotenv_path='.env')  # Default is '.env'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ.get(\"HF_API_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
    "from haystack.utils import ComponentDevice, Device\n",
    "\n",
    "device = ComponentDevice.from_str(\"cuda\")\n",
    "\n",
    "document_store = ChromaDocumentStore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "\n",
    "from haystack_integrations.components.embedders.jina import JinaTextEmbedder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack_integrations.components.embedders.fastembed import FastembedTextEmbedder\n",
    "\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from haystack.components.generators import HuggingFaceLocalGenerator\n",
    "\n",
    "def load_model(retriever):\n",
    "    global query_pipeline\n",
    "    cache_dir= \"embed_cache\"\n",
    "    generator = HuggingFaceLocalGenerator(\"mistralai/Mistral-7B-Instruct-v0.2\",                                      \n",
    "                                              huggingface_pipeline_kwargs={\"device_map\":\"auto\",\n",
    "                                                            \"model_kwargs\":{\"load_in_4bit\":True,\n",
    "                                                              \"bnb_4bit_use_double_quant\":True,\n",
    "                                                              \"bnb_4bit_quant_type\":\"nf4\",\n",
    "                                                              \"bnb_4bit_compute_dtype\":torch.bfloat16,\n",
    "                                                                           }},\n",
    "                                              generation_kwargs={\n",
    "                                                                \"max_new_tokens\": 400,    # Controls response length\n",
    "                                                                \"do_sample\": True,\n",
    "                                                                \"temperature\": 0.3,\n",
    "                                                                \"top_p\": 0.9})\n",
    "    \n",
    "    generator.warm_up()\n",
    "    \n",
    "    prompt_template = prompt_template = \"\"\"\n",
    "    <s>[INST]Please answer the following question using only the information in the provided context.\n",
    "    \n",
    "    - If the answer is explicitly contained within the context, provide a complete response and clearly state the page number(s) referenced.\n",
    "    - If the answer cannot be determined from the context, respond with: \"The answer cannot be determined from the given context.\"\n",
    "    \n",
    "    Context:\n",
    "    \n",
    "    {% for doc in documents %}\n",
    "    Page {{ doc.meta['page_number'] }}:\n",
    "    {{ doc.content }}\n",
    "    {% endfor %}\n",
    "    \n",
    "    Question: {{ question }}\n",
    "    \n",
    "    </s>[/INST]\n",
    "    \"\"\"\n",
    "    \n",
    "    text_embedder = JinaTextEmbedder(model=\"jina-embeddings-v2-base-en\")\n",
    "    text_embedder = FastembedTextEmbedder(\n",
    "    \tmodel=\"jinaai/jina-embeddings-v2-base-en\",\n",
    "    \tcache_dir=cache_dir,\n",
    "    )\n",
    "    \n",
    "    prompt_builder = PromptBuilder(template=prompt_template)\n",
    "    query_pipeline = Pipeline()\n",
    "    query_pipeline.add_component(\"text_embedder\",text_embedder)\n",
    "    query_pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "    query_pipeline.add_component(\"retriever\", retriever)\n",
    "    query_pipeline.add_component(\"generator\", generator)\n",
    "    \n",
    "    query_pipeline.connect(\"text_embedder.embedding\", \"retriever\")\n",
    "    query_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "    query_pipeline.connect(\"prompt_builder.prompt\", \"generator.prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from haystack import Pipeline\n",
    "\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import PyPDFToDocument,DOCXToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack_integrations.components.retrievers.chroma import ChromaEmbeddingRetriever\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack_integrations.components.embedders.fastembed import FastembedSparseTextEmbedder,FastembedTextEmbedder\n",
    "from haystack_integrations.components.embedders.fastembed import FastembedSparseDocumentEmbedder,FastembedDocumentEmbedder\n",
    "\n",
    "\n",
    "def embedding_doc(file_path):\n",
    "    # file_path = \"docs/steel.pdf\"\n",
    "    \n",
    "    cache_dir= \"embed_cache\"\n",
    "    document_embedder = FastembedDocumentEmbedder(\n",
    "        model=\"jinaai/jina-embeddings-v2-base-en\",\n",
    "        cache_dir=cache_dir,\n",
    "        threads=2\n",
    "    )\n",
    "    document_embedder.warm_up()\n",
    "    \n",
    "    fetcher = LinkContentFetcher()\n",
    "    \n",
    "    if file_path:\n",
    "        if file_path.lower().endswith('.pdf'):\n",
    "            converter = PyPDFToDocument()\n",
    "        elif file_path.lower().endswith(('.doc', '.docx')):\n",
    "            converter = DOCXToDocument()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type. Please provide a PDF or Word document.\")\n",
    "    # remove repeated substrings to get rid of headers/footers\n",
    "    cleaner = DocumentCleaner(remove_repeated_substrings=True)\n",
    "    \n",
    "    # Since jina-v2 can handle 8192 tokens, 500 words seems like a safe chunk size\n",
    "    splitter = DocumentSplitter(split_by=\"word\", split_length=500)\n",
    "    \n",
    "    # DuplicatePolicy.SKIP is optional but helps avoid errors if you want to re-run the pipeline\n",
    "    writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "    \n",
    "    retriever = ChromaEmbeddingRetriever(document_store=document_store)\n",
    "    \n",
    "    indexing_pipeline = Pipeline()\n",
    "    \n",
    "    # indexing_pipeline.add_component(instance=fetcher, name=\"fetcher\")\n",
    "    indexing_pipeline.add_component(instance=converter, name=\"converter\")\n",
    "    indexing_pipeline.add_component(instance=cleaner, name=\"cleaner\")\n",
    "    indexing_pipeline.add_component(instance=splitter, name=\"splitter\")\n",
    "    indexing_pipeline.add_component(instance=document_embedder, name=\"embedder\")\n",
    "    indexing_pipeline.add_component(instance=writer, name=\"writer\")\n",
    "    \n",
    "    # indexing_pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
    "    indexing_pipeline.connect(\"converter.documents\", \"cleaner.documents\")\n",
    "    indexing_pipeline.connect(\"cleaner.documents\", \"splitter.documents\")\n",
    "    indexing_pipeline.connect(\"splitter.documents\", \"embedder.documents\")\n",
    "    indexing_pipeline.connect(\"embedder.documents\", \"writer.documents\")\n",
    "    \n",
    "    #indexing_pipeline.run(data={\"fetcher\": {\"urls\": urls}})\n",
    "    indexing_pipeline.run({\"converter\": {\"sources\": [Path(file_path)]}})\n",
    "    load_model(retriever)\n",
    "\n",
    "    # print(\"Embedding Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36e0411b6e24c159e969a54e5fc9c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b760a37e6ea4937a3069bdb504c6e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Directory for uploaded files\n",
    "save_directory = \"llama_test/voila_uploaded_files\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Widgets\n",
    "upload_widget = widgets.FileUpload(accept='', multiple=False)\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Variables to store state\n",
    "uploaded_file_path = None\n",
    "\n",
    "\n",
    "# Step 1: File Upload Handler\n",
    "def on_file_upload(change):\n",
    "    global uploaded_file_path\n",
    "    with output_widget:\n",
    "        clear_output()\n",
    "        if upload_widget.value:\n",
    "            # Access the uploaded file\n",
    "            for file_info in upload_widget.value:\n",
    "                file_name = file_info['name']\n",
    "                content = file_info['content']  # File content as bytes\n",
    "\n",
    "                # Save file to disk\n",
    "                uploaded_file_path = os.path.join(save_directory, file_name)\n",
    "                with open(uploaded_file_path, 'wb') as f:\n",
    "                    f.write(content)\n",
    "                \n",
    "                print(f\"Uploaded file '{file_name}' has been saved at {uploaded_file_path}.\")\n",
    "                \n",
    "                # Process the file (e.g., create embeddings)\n",
    "                embedding_doc(uploaded_file_path)\n",
    "                print(\"File Loaded, Model Ready for Use!\")\n",
    "\n",
    "# Link handler to widget\n",
    "upload_widget.observe(on_file_upload, names='value')\n",
    "\n",
    "# Display widgets\n",
    "display(upload_widget, output_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "# Styling for custom widgets\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    "    .custom-container {\n",
    "        border: 2px solid #4CAF50;\n",
    "        border-radius: 15px;\n",
    "        padding: 20px;\n",
    "        background-color: #f9f9f9;\n",
    "        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "    .custom-header {\n",
    "        font-family: 'Verdana';\n",
    "        font-size: 20px;\n",
    "        color: #4CAF50;\n",
    "        text-align: center;\n",
    "        margin-bottom: 15px;\n",
    "    }\n",
    "    .custom-input {\n",
    "        margin-top: 10px;\n",
    "    }\n",
    "    .custom-output {\n",
    "        padding: 10px;\n",
    "        border-radius: 10px;\n",
    "        margin-top: 15px;\n",
    "        background-color: #ffffff;\n",
    "    }\n",
    "    .custom-button {\n",
    "        font-family: 'Arial';\n",
    "        font-size: 14px;\n",
    "        background-color: #4CAF50;\n",
    "        color: white;\n",
    "        border: none;\n",
    "        padding: 8px 16px;\n",
    "        border-radius: 10px;\n",
    "        cursor: pointer;\n",
    "    }\n",
    "    .custom-button:hover {\n",
    "        background-color: #45a049;\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Widgets for the UI\n",
    "question_widget = widgets.Text(\n",
    "    description=\"Question:\",\n",
    "    placeholder=\"Type your question here...\",\n",
    "    layout=widgets.Layout(width=\"90%\")\n",
    ")\n",
    "\n",
    "output_widget = widgets.Output(\n",
    "    layout=widgets.Layout(padding=\"10px\", width=\"90%\")\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description=\"Submit Question\",\n",
    "    button_style=\"\",\n",
    "    layout=widgets.Layout(width=\"30%\"),\n",
    "    style={\"button_color\": \"#4CAF50\", \"font_weight\": \"bold\"}\n",
    ")\n",
    "\n",
    "# Function to handle question submission\n",
    "def on_question_submit(button):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()  # Clear previous output\n",
    "        question = question_widget.value\n",
    "        try:\n",
    "            # Simulate RAG model response\n",
    "            result = query_pipeline.run(data={\n",
    "                \"text_embedder\": {\"text\": question},\n",
    "                \"retriever\": {\"top_k\": 20},\n",
    "                \"prompt_builder\": {\"question\": question},\n",
    "                \"generator\": {\"generation_kwargs\": {\"max_new_tokens\": 600}}\n",
    "            })\n",
    "            answer = result['generator']['replies'][0]\n",
    "            \n",
    "            # Display question and answer with custom formatting\n",
    "            display(widgets.HTML(f\"\"\"\n",
    "            <div style=\"font-family: 'Arial'; font-size: 18px; color: blue; margin-bottom: 10px;\">\n",
    "                <strong>Q:</strong> {question}\n",
    "            </div>\n",
    "            <div style=\"font-family: 'Courier New'; font-size: 16px; color: darkgreen; margin-top: 5px;\">\n",
    "                <strong>A:</strong> {answer}\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "        except Exception as e:\n",
    "            # Display a friendly error message if something goes wrong\n",
    "            display(widgets.HTML(f\"<p style='color: red;'>An error occurred: {str(e)}</p>\"))\n",
    "\n",
    "# Attach the button click event\n",
    "submit_button.on_click(on_question_submit)\n",
    "\n",
    "# Restore standard output for UI purposes\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# Display the UI\n",
    "display(HTML(custom_css))  # Inject custom styles\n",
    "container = widgets.VBox(\n",
    "    [\n",
    "        widgets.HTML(\"<div class='custom-header'>Document Q&A System</div>\"),\n",
    "        question_widget,\n",
    "        submit_button,\n",
    "        output_widget\n",
    "    ],\n",
    "    layout=widgets.Layout(\n",
    "        align_items=\"center\",\n",
    "        width=\"100%\",\n",
    "        padding=\"20px\",\n",
    "        border=\"2px solid #4CAF50\",\n",
    "        border_radius=\"15px\",\n",
    "        box_shadow=\"0px 4px 6px rgba(0, 0, 0, 0.1)\"\n",
    "    )\n",
    ")\n",
    "display(container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = [\n",
    "#     # \"What constitutes force majeure or excused delay?\",\n",
    "#     # \"Are there any stipulations or restrictions on the use of owner equipment?\",\n",
    "#     # \"Are there any daily or weekly or other recurring meetings?\",\n",
    "#     # \"Are there reporting requirements?\",\n",
    "#     # \"What are the schedule dates by which the contractor must perform?\",\n",
    "#     # \"What are the contractor’s warranty obligations?\",\n",
    "#     # \"How long is the contractor’s warranty?\",\n",
    "#     # \"When does the contractor have to provide notice?\",\n",
    "#     # \"What type of insurance is the contractor obligated to have in place or obtain?\",\n",
    "#     # \"When is the contractor allowed an adjustment or increase to the contract price or schedule?\",\n",
    "#     # \"The project schedule to be delivered by the contractor.\",\n",
    "#     # \"The type of warranty that the contractor provides for the work it is furnishing.\",\n",
    "#     # \"The time period in which the contractor is to provide notice of a change to schedule or price.\",\n",
    "#     # \"The information the contractor is to provide with a notice of delay.\",\n",
    "#     # \"Is there more than one notice to be provided regarding a delay?\",\n",
    "#     # \"The type of insurance the contractor is to provide.\",\n",
    "#     # \"The method of notice that must be used by the contractor when sending notice to its customer.\",\n",
    "#     # \"The required procedure to resolve a dispute under the contract.\",\n",
    "#     # \"The safety responsibilities of the contractor for the site.\",\n",
    "#     \"What are all the testing requirements, explain\"\n",
    "#     # \"The safety responsibilities of the contractor for the site.\"\n",
    "# ]\n",
    "\n",
    "# for question in questions:\n",
    "#     result = query_pipeline.run(data={\n",
    "#         \"text_embedder\": {\"text\": question},\n",
    "#         \"retriever\": {\"top_k\": 20},\n",
    "#         \"prompt_builder\": {\"question\": question},\n",
    "#         \"generator\": {\"generation_kwargs\": {\"max_new_tokens\": 600}}\n",
    "#     })\n",
    "    \n",
    "#     print(f\"Question: {question}\")\n",
    "#     print(result['generator']['replies'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
